{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "YOLO_with_Vertical_Reframing.ipynb",
      "mount_file_id": "1E2ESnre4_Iar2Z0Dqjg6MRx9Ub5_J1_3",
      "authorship_tag": "ABX9TyNA2vWJywM5Q/C01jidfDYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jj132535/YOLOv8-human-video-detection/blob/main/YOLO_with_Vertical_Reframing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyYAML\n",
        "!pip install ultralytics\n",
        "!pip install roboflow"
      ],
      "metadata": {
        "id": "pzroSdWpQ6Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import ultralytics\n",
        "import cv2\n",
        "import numpy as np\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "0xAz4S9sROLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add your video path\n",
        "video_path = '/content/dreamcatcher.mp4'\n",
        "\n",
        "# !! PUT yolov8_trained_model.pt FILE INTO /content/ !!\n",
        "trained_model_path = '/content/yolov8_trained_model.pt' #trained model\n",
        "\n",
        "output_video_path = '/content/output_video_chuu.mp4'"
      ],
      "metadata": {
        "id": "uQkrvpmORXSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 불러오기\n",
        "model = YOLO(trained_model_path)"
      ],
      "metadata": {
        "id": "su0XWvCyGXc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(source=video_path, stream=True)"
      ],
      "metadata": {
        "id": "-VN1_l2OGYBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 비디오 저장 설정 (세로 비율 9:16)\n",
        "width, height = 1080, 1920\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, 30, (width, height))\n",
        "\n",
        "# 초기 설정\n",
        "frame_count = 0\n",
        "\n",
        "# 각 프레임에 대해 탐지된 객체를 기준으로 리프레이밍\n",
        "for r in results:\n",
        "    frame = r.orig_img  # 원본 프레임 가져오기\n",
        "    bboxes = r.boxes.xywh if hasattr(r, 'boxes') and r.boxes is not None else None\n",
        "    frame_count += 1\n",
        "\n",
        "    if frame_count >= 3:  # 첫 두 프레임은 건너뜀\n",
        "        if bboxes is not None and bboxes.shape[0] > 0:\n",
        "            # numpy 배열로 변환하여 사용\n",
        "            bboxes = bboxes.cpu().numpy()\n",
        "\n",
        "            # 중앙에 가장 가까운 객체 선택\n",
        "            frame_center_x = frame.shape[1] / 2\n",
        "            closest_bbox = min(bboxes, key=lambda bbox: abs(bbox[0] - frame_center_x))\n",
        "            x_center, y_center, box_width, box_height = closest_bbox\n",
        "\n",
        "            # 탐지된 객체의 중심을 기준으로 세로로 크롭\n",
        "            x1 = int(x_center - width / 2)\n",
        "            x2 = int(x_center + width / 2)\n",
        "            y1 = 0\n",
        "            y2 = frame.shape[0]  # 원래 높이를 유지\n",
        "\n",
        "            # 프레임의 경계를 벗어나는 경우 조정\n",
        "            x1 = max(0, x1)\n",
        "            x2 = min(frame.shape[1], x2)\n",
        "\n",
        "            cropped_frame = frame[y1:y2, x1:x2]  # 세로로 크롭된 프레임\n",
        "            resized_frame = cv2.resize(cropped_frame, (width, height))\n",
        "\n",
        "            # FPS를 원본 비디오와 동일하게 설정하여 속도 문제 해결\n",
        "            out.write(resized_frame)  # 비디오에 작성\n",
        "        else:\n",
        "            print(f\"No detections in frame {frame_count}\")\n"
      ],
      "metadata": {
        "id": "FA5yv0RsSFA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VideoWriter 객체 닫기\n",
        "out.release()"
      ],
      "metadata": {
        "id": "isQeD6QpSH35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Video reframing complete and saved to:\", output_video_path)"
      ],
      "metadata": {
        "id": "CULfgOMWSKQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}